docs=["t1.txt","t2.txt","t3.txt","t4.txt","t5.txt","t6.txt"]
s=[]
for i in range(len(docs)):
  f=open(docs[i],encoding="UTF-8")
  r=f.read()
  s.append(r)
  f.seek(0)
print(s[0])

#tokenisation and normalisation
from nltk.tokenize import word_tokenize
import nltk
from nltk.corpus import stopwords
nltk.download('stopwords')
nltk.download('punkt')

#remove punctuations
punc = '''!()-[]{};:'"\, <>./?@#$%^&*_~'''
for i in range(len(s)):
  for word in s[i]:
    if word in punc:
      s[i]=s[i].replace(word," ")
    s[i]=s[i].replace("\n"," ")
    s[i]=s[i].lower()
print(s[0])
#tokenisation & stop words removal
token=[]
for i in s:
    tk=word_tokenize(i)
    token.append(tk)
res=[]
for i in token:
  for word in i:
    if not word in stopwords.words('english') and not word in res:
      res.append(word)
res.sort()
for k in range(len(s)):
  s[k]=s[k].split()
print(s[0])
def nonpos(p,s,ind):
  np=[]
  for i in range(len(s)):
    if p in s[i]:
       np.append(ind+i+1)
  return np
def block(s,l,u,ind):
     b={}
     for i in s[l:u]:
       print(i)
       for j in i:
         if j not in b.keys():
           b[j]=nonpos(j,s[l:u],ind)
     return b
def blocksort(b):
  keys=list(b.keys())
  keys.sort()
  b={i:b[i] for i in keys}
  return b
def blockmerge(b1,b2):
  for i in b1.keys():
    if i in b2.keys():
      b1[i]=b1[i].extend(b2[i])
      b2.pop(i)
  if(len(b2)):
    for i in b2.keys():
      b1[i]=b2[i]
  return b1
b1=blocksort(block(s,0,3,0))
b2=blocksort(block(s,3,len(s),3))
print(b1)
print(b2)
b1=blockmerge(b1,b2)
print(b1)
